Dataset: Polarity
    Metadata:
        Title: "Movie Review Polarity" 
        Unique-identifier: Movie_Review_Polarity
        Version: v0001
        Description:  
            Purpose: 
                "The dataset was created to enable research on predicting sentiment polarity—i.e., given a piece of English text, predict whether
                it has a positive or negative affect—or stance—toward its topic.The dataset was created intentionally with that task in mind, 
                focusing on movie reviews as a place where affect/sentiment is frequently expressed." 
            Tasks: "Classification"  
        Citation: 
            "Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using
            subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Annual
            Meeting of the Association for Computational Linguistics. 271."
        Uses: 
            Past Uses:
               "At the time of publication, only the original paper (http://xxx.lanl.
                gov/pdf/cs/0409058v1). Between then and 2012, a collection of papers 
                that used this dataset was maintained at http://www.cs.cornell.
                edu/people/pabo/movie%2Dreview%2Ddata/otherexperiments.html."
            Recommneded Uses:
                "The dataset could be used for anything related to modeling or
                understanding movie reviews. For instance, one may induce a
                lexicon of words/phrases that are highly indicative of sentiment
                polarity, or learn to automatically generate movie reviews"
            Non-recommended Uses:
                "This data is collected solely in the movie review domain, so
                systems trained on it may or may not generalize to other sentiment prediction tasks. 
                Consequently, such systems should not— without additional verification—be used to make consequential
                decisions about people"
        Distribution: 
            Is public?: yes
            How is distributed: 
                "The dataset is distributed on Bo Pang’s webpage at Cornell: http:
                //www.cs.cornell.edu/people/pabo/movie-review-data. The dataset does
                not have a DOI and there is no redundant archive. The dataset was first released in 2002."
            Distribution license: 
                "The crawled data copyright belongs to the authors of the reviews
                unless otherwise stated. There is no license, but there is a request
                to cite the corresponding paper if the dataset is used: Thumbs up?
                Sentiment classification using machine learning techniques. Bo
                Pang, Lillian Lee, and Shivakumar Vaithyanathan. Proceedings
                of EMNLP, 2002."
        Area: Sentiment
        Tags: Movie Review Sentiment Classification
        Authoring:
            Authors:
                Name Bo_Pong email "XXXX@email.com"
                Name Lillian_Lee	email "XXXX@email.com"
            Founders:
                Name National_Science_Fundations type mixed
                Name Deparment_of_the_Interior type public 
                Name National_Business_Center type mixed
                Name Cornell_University type mixed
                Name Sloan_Fundaiton type private 
            License Information: "
                    The crawled data copyright belongs to the authors of the reviews
                    unless otherwise stated. There is no license, but there is a request
                    to cite the corresponding paper if the dataset is used: Thumbs up?
                    Sentiment classification using machine learning techniques. Bo
                    Pang, Lillian Lee, and Shivakumar Vaithyanathan. Proceedings
                    of EMNLP, 2002." 
            Maintenance:
                Maintainer:
                    Name Bo_Pong email "XXXX@email.com"
                Erratum? 
                    "Since its initial release (v0.9) there have been three later releases
                    (v1.0, v1.1, and v2.0). There is not an explicit erratum, but updates and
                    known errors are specified in higher version README
                    and diff files. There are several versions of these: v1.0:
                    http://www.cs.cornell.edu/people/pabo/movie-review-data/README;
                    v1.1: http://www.cs.cornell.edu/people/pabo/movie%2Dreview%
                    2Ddata/README.1.1 and http://www.cs.cornell.edu/people/pabo/
                    movie-review-data/diff.txt; v2.0: http://www.cs.cornell.edu/people/pabo/
                    movie%2Dreview%2Ddata/poldata.README.2.0.txt. Updates are listed
                    on the dataset web page. (This datasheet largely summarizes
                    these sources.)"
                Version support 
                    "The dataset has already been updated; older versions are kept
                    around for consistency."
                Contribution guides: 
                    "The curators of the dataset, Bo Pang and Lillian lee, can be contacted at 
                    https://sites.google.com/site/bopang42/ and http://www.cs.
                    cornell.edu/home/llee, respectively.
                    Is there an erratum? If so, please provid"

    Composition:
         Description: 
            "The instances are movie reviews extracted from newsgroup postings,
            together with a sentiment polarity rating for whether the text
            corresponds to a review with a rating that is either strongly positive (high number of stars)
            or strongly negative (low number of  stars). The sentiment polarity rating is binary {positive, negative}."
         Total number of instances: 64702

         Instances: 
                Instance: MovieReviews
                     Description: 
                        "Each instance consists of the text associated with the review, with
                        obvious ratings information removed from that text (some errors
                        were found and later fixed). The text was down-cased and HTML
                        tags were removed. Boilerplate newsgroup header/footer text was
                        removed. Some additional unspecified automatic filtering was
                        done. Each instance also has an associated target value: a positive
                        (+1) or negative (-1) sentiment polarity rating based on the number of 
                        stars that that review gave (details on the mapping from
                        number of stars to polarity is given below in “Data Preprocessing”). 
                        There is total number of 64702 sentences analyzed"
                     Type: Record_Data
                     Number of attributes: 6
                     Related Labels: Tag
                     Attributes:
                        attribute: fold_id
                            description: "Folder Id containing the text inside the dataset " 
                            completeness: 100 
                            count: 64702
                            ofType: Categorical
                        attribute: cv_tag
                            description: "Author file id containint the text inside the dataset " 
                            completeness: 100 
                            count: 64702
                            ofType: Categorical 
                        attribute: html_id
                        description: "Author file ID separated by pos and negative labels " 
                          completeness: 100 
                          count: 64702 
                          ofType: Categorical 
                        attribute: sent_id
                            description: "Sentence id inside every file " 
                            completeness: 100 
                            count: 64702 
                            ofType: Categorical 
                            attribute: text
                        description: "The text extracted from the revies of IMDB " 
                        completeness: 100 
                        count: 64702
                        ofType: Categorical 
                        attribute: tag
                          description: "The label annotated by the reviewrs " 
                          completeness: 100 
                          ofType: Categorical
                           Categoric Distribution:
                            "pos: 50%
                             neg: 50%"
                    Instance Statistics:
                        Pair Plot: "Categorical distribution of attribute tag" 
                    Data Quality:
                            Sparsity: 0
                            Compeleteness: 100
                            Class Balance "attribute 'tag': 50% positive, 50% negative"
                
                Dependencies: 
                    Description: "The dataset is entirely self-contained."
                Is sample: 
                    "The sample of instances collected is English movie reviews from
                    the rec.arts.movies.reviews newsgroup, from which a
                    “number of stars” rating could be extracted. The sample is limited
                    to forty reviews per unique author in order to achieve broader
                    coverage by authorship. Beyond that, the sample is arbitrary."     
                Data Splits: 
                    "The instances come with a “cross-validation tag” to enable replication of 
                    cross-validation experiments; results are measured in
                    classification accuracy. " 

     Social Concerns:
         Privacy:
            Legal Issues: "Not known by the authors"
        Sensitive Data: 
            Description: "Some movie reviews might contain moderately inappropriate or
            offensive language, but we do not expect this to be the norm"  
            Instance belongs to people:
                Are there protecte groups? "No"
        Social Impact: 
            "Some personal information is retained from the newsgroup posting
            in the “raw form” of the dataset (as opposed to the “preprocessed” version, 
            in which these are automatically removed), including the name and email address 
            the author posted under (note that these are already public on the internet newsgroup 
            archive)."


     Data Provenance:
         Curation Rationale: 
            "The data was mostly observable as raw text, except that the
            labels were extracted by the process described below. The
            data was collected by downloading reviews from the IMDb
            archive of the rec.arts.movies.reviews newsgroup, at
            http://reviews.imdb.com/Reviews."
          Data Sources:
            Source: IMDb
            Description:
                "The sample of instances collected is English movie reviews from
                the rec.arts.movies.reviews newsgroup, from which a
                “number of stars” rating could be extracted. The sample is limited
                to forty reviews per unique author in order to achieve broader
                coverage by authorship. Beyond that, the sample is arbitrar" 
            Related Instances: MovieReviews
            How data is collected: "Unkown to the authors"
            Who collects the data: "Uknown to the authors"
            Noise Sources: "Uknown from the source, see preprocessing" 
            Privacy: 
             "Individuals were not aware of data collection. The data was crawled from public web sources,
             and the authors of the posts presumably knew that their posts would be public, but the authors 
             werenot explicitly informed that their posts were to be used in this way."
         Data Preprocessing: 
            Labeling process: labelproces1
            Description: "Desc of lbel"
            Type: Entity annotation
            Labels:
                Label: Tag
                Description: "The label is the positive/negative sentiment polarity rating derived
                from the star rating"
            Mapping: tag
            Who annotates the data: "320 voluunteer reviewers"
            Label Requeriments "The process requeriments"